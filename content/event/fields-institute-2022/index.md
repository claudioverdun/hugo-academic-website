---
abstract: In many applications, solutions of numerical problems are required to
  be nonnegative. For example, when one seeks to retrieve pixel intensity values
  or the chemical concentration of a substance. In this context, nonnegative
  least squares is a ubiquitous tool. Despite vast efforts, since the seminal
  work of Lawson and Hanson in the '70s, the nonnegativity assumption is still
  an obstacle for the scalability of many off-the-shelf solvers. Recently, in a
  different context, we started to see numerous developments in deep neural
  networks, where the training of overparametrized models via gradient descent
  lead to surprising generalization properties and to the retrieval of
  regularized solutions such as low-rank matrices. In this talk, I will connect
  the problem of nonnegative least squares with recent progress in the field of
  implicit bias of the gradient descent. This talk is based on joint work with
  Johannes Maly and Hung-Hsu Chou.
slides: ""
url_pdf: ""
summary: An example talk using Wowchemy's Markdown slides feature.
date_end: 2022-05-09T20:30:00.000Z
event_url: http://www.fields.utoronto.ca/activities/21-22/data-harmonic
authors: []
url_video: https://www.youtube.com/watch?v=aNumBk4W2YM
date: 2022-05-09T20:00:00.000Z
featured: false
url_slides: ""
address:
  street: 450 Serra Mall
  city: Stanford
  region: CA
  postcode: "94305"
  country: United States
title: "Nonnegative Least Squares: An overparametrized point of view"
location: Fields Institute
links: []
event: Workshop on Computational Harmonic Analysis and Linear Algebra
publishDate: 2017-01-01T00:00:00Z
tags: []
projects: []
image:
  caption: ""
  focal_point: Right
url_code: ""
all_day: false
---
